{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WhatApp Chat Analysis using Python",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct_E1ZPzBmkL",
        "colab_type": "text"
      },
      "source": [
        "# Parneet's Whatapp chat analysis using python\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0eOmerDBQc_",
        "colab_type": "text"
      },
      "source": [
        "This project do the WA chat analysis using pandas, numpy, matplotlib etc libraries...\n",
        "\n",
        "Firstly there is a need to have the chat .txt file\n",
        "\n",
        "For that:\n",
        "Open Whatsapp group chat\n",
        "Settings\n",
        "Click on Export Chat\n",
        "Click on without media(for simplifying)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Enh9VIYPnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jq5_jkMBE8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing libraries\n",
        "from os import path\n",
        "from PIL import Image\n",
        "import emoji\n",
        "import plotly.express as px\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK-mVQNDcqNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "% matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_IVxlHe_vr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone https://github.com/amueller/word_cloud.git\n",
        "% cd word_cloud\n",
        "! pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccX8HRn5BL89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#specifying pattern \n",
        "def DateAndTime(s):\n",
        "    pattern = '^\\[([0-9]+)([\\/-])([0-9]+)([\\/-])([0-9]+)[,]? ([0-9]+):([0-9][0-9]):([0-9][0-9])[ ]?(AM|PM|am|pm)?\\]'\n",
        "    out = re.match(pattern, s)\n",
        "    if out:\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E_Pu7LLWZyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DateAndTime(\"[01/09/20, 10:48:16 AM] ‚Ä™+91¬†99180¬†56238‚Ä¨: Most welcome, thank you for being a part of the initiative....\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLR8M2dhBz7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ToKnowAuthor(s):\n",
        "    pattern = [\n",
        "        '([\\w]+):',                        # First Name pattern\n",
        "        '([\\w]+[\\s]+[\\w]+):',              # pattern of First Name + Last Name\n",
        "        '([\\w]+[\\s]+[\\w]+[\\s]+[\\w]+):',    # First Name + Middle Name + Last Name\n",
        "        '([+]\\d{2} \\d{5} \\d{5}):',         # Mobile Number (India)\n",
        "        '([+]\\d{2} \\d{3} \\d{3} \\d{4}):',   # Mobile Number (US)\n",
        "        '([\\w]+)[\\u263a-\\U0001f999]+:',    # Name and Emoji  pattern            \n",
        "    ]\n",
        "    pattern = '^' + '|'.join(pattern)\n",
        "    out = re.match(pattern, s)\n",
        "    if out:\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6WSoM1vB1zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getingInfo(data):   \n",
        "    splitLine = data.split('] ')\n",
        "    dateTime = splitLine[0]\n",
        "    if ',' in dateTime:\n",
        "      date, time = dateTime.split(',') \n",
        "    else:\n",
        "      date, time = dateTime.split(' ') \n",
        "    message = ' '.join(splitLine[1:])\n",
        "    if ToKnowAuthor(message): \n",
        "        splitMessage = message.split(': ') \n",
        "        author = splitMessage[0] \n",
        "        message = ' '.join(splitMessage[1:])\n",
        "    else:\n",
        "        author = None\n",
        "    return date, time, author, message\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgfGiHyGB68i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ChatPath = '/content/_chat.txt' # upload file to notebook \n",
        "Data = []\n",
        "with open(ChatPath, encoding=\"utf-8\") as fp:\n",
        "    fp.readline() # First line skipped cuz it contains encryption info\n",
        "    fp.readline()\n",
        "    fp.readline()\n",
        "    messageBuffer = [] \n",
        "    date, time, author = None, None, None\n",
        "    while True:\n",
        "        data = fp.readline()\n",
        "        if not data: \n",
        "            break \n",
        "        data = data.strip()\n",
        "        if DateAndTime(data): \n",
        "            if len(messageBuffer) > 0: \n",
        "                Data.append([date, time, author, ' '.join(messageBuffer)]) \n",
        "            messageBuffer.clear() \n",
        "            date, time, author, message = getingInfo(data) \n",
        "            messageBuffer.append(message) \n",
        "        else:\n",
        "          data= (data.encode('ascii', 'ignore')).decode(\"utf-8\")\n",
        "          if DateAndTime(data): \n",
        "            if len(messageBuffer) > 0: \n",
        "                Data.append([date, time, author, ' '.join(messageBuffer)]) \n",
        "            messageBuffer.clear() \n",
        "            date, time, author, message = getingInfo(data) \n",
        "            messageBuffer.append(message) \n",
        "          else:\n",
        "            messageBuffer.append(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dVEi09eB8qK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dateconv(date):\n",
        "  year=''\n",
        "  if '-' in date:\n",
        "    year = date.split('-')[2]\n",
        "    if len(year) == 4:\n",
        "      return datetime.datetime.strptime(date, \"[%d-%m-%Y\").strftime(\"%Y-%m-%d\")\n",
        "    elif len(year) ==2:\n",
        "      return datetime.datetime.strptime(date, \"[%d-%m-%y\").strftime(\"%Y-%m-%d\")\n",
        "  elif '/' in date:\n",
        "    year = date.split('/')[2]\n",
        "    if len(year) == 4:\n",
        "      return datetime.datetime.strptime(date, \"[%d/%m/%Y\").strftime(\"%Y-%m-%d\")\n",
        "    if len(year) ==2:\n",
        "      return datetime.datetime.strptime(date, \"[%d/%m/%y\").strftime(\"%Y-%m-%d\")\n",
        "df = pd.DataFrame(Data, columns=['Date', 'Time', 'Author', 'Text']) \n",
        "df[\"Date\"] = df[\"Date\"].apply(dateconv)\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxnSCcaGCPam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGfkDZ5iCgqO",
        "colab_type": "text"
      },
      "source": [
        "## telling the senders in the given chat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEttBBKZCQfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Author.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcM2IhXmC0zY",
        "colab_type": "text"
      },
      "source": [
        "Removing the messages created by None"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA4b5nSGC6Kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.dropna()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzPSOF7yDosE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Author.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-32IxysDuts",
        "colab_type": "text"
      },
      "source": [
        "Done :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdG_QS-DFgMt",
        "colab_type": "text"
      },
      "source": [
        "Analysing the chat in detail!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-RYhorEOfZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_texts = df.shape[0]\n",
        "print(total_texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKDrfBB2Ovfa",
        "colab_type": "text"
      },
      "source": [
        "To see media texts...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8kZeRLADzxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "media_texts = df[df['Text'] == 'image omitted'].shape[0]\n",
        "print(media_texts)\n",
        "# in our case 0 as we have excluded media texts in our chat file..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftegdpLrDgF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count(text):\n",
        "\n",
        "    emoji_list = []\n",
        "    data = regex.findall(r'\\X', text)\n",
        "    for word in data:\n",
        "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
        "            emoji_list.append(word)\n",
        "\n",
        "    return emoji_list\n",
        "\n",
        "df[\"emoji\"] = df[\"Text\"].apply(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukq2MWKPUHWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emojis = sum(df['emoji'].str.len())\n",
        "print(emojis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZdFz-0UYaTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Analysis\")\n",
        "print(\"Texts:\",total_texts)\n",
        "print(\"Media:\",media_texts)\n",
        "print(\"Emojis:\",emojis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj3J0Bb-usX4",
        "colab_type": "text"
      },
      "source": [
        "## Getting info abt media, text  and sticker messages in chat file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ9Cd-_8uxT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "media_texts_df = df[(df['Text'] == 'image omitted')|(df['Text'] == 'video omitted')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7dTGeFOTono",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sticker_texts_df = df[df['Text'] == 'sticker omitted']\n",
        "sticker_texts_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_bqcU6bu6ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_df = df.drop(media_texts_df.index)\n",
        "texts_df = texts_df.drop(sticker_texts_df.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZflAweBoGFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd5Bu3fOvKWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_df['Letter_Count'] = texts_df['Text'].apply(lambda s : len(s))\n",
        "texts_df['Word_Count'] = texts_df['Text'].apply(lambda s : len(s.split(' ')))\n",
        "texts_df[\"TextCount\"]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Dn_glCLPhp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_df.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c5r6rbGQnAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_df[\"emojicount\"]= df['emoji'].str.len()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVLnOAKzvasf",
        "colab_type": "text"
      },
      "source": [
        "#Participants texting analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VF29K-svWEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = texts_df.Author.unique()\n",
        "for i in range(len(l)):\n",
        "  req_df= texts_df[texts_df[\"Author\"] == l[i]]\n",
        "  print(f'Stats of {l[i]} -')\n",
        "  print('Total Messages Sent', req_df.shape[0])\n",
        "  words_per_message = (np.sum(req_df['Word_Count']))/req_df.shape[0]\n",
        "  print('Words per message', words_per_message)\n",
        "  stickers = sticker_texts_df[sticker_texts_df['Author'] == l[i]].shape[0]\n",
        "  print('Sticker Messages Sent', stickers)\n",
        "  media = media_texts_df[media_texts_df['Author'] == l[i]].shape[0]\n",
        "  print('Media Messages Sent', media)\n",
        "  emojis = sum(req_df['emoji'].str.len())\n",
        "  print('Emojis Sent', emojis) \n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGTpyoNbTCLI",
        "colab_type": "text"
      },
      "source": [
        "# Lets have an analysis on emojis' usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_0BHwJ0zvoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_emojis_list = list(set([a for b in texts_df.emoji for a in b]))\n",
        "total_emojis = len(total_emojis_list)\n",
        "print(total_emojis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTZMMc2cz5Bk",
        "colab_type": "text"
      },
      "source": [
        "### Most used emoji"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxVBAJ_JotaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_emojis_list = list([a for b in texts_df.emoji for a in b])\n",
        "emoji_dict = dict(Counter(total_emojis_list))\n",
        "emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "print(emoji_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxg5R_7tuWh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emoji_df = pd.DataFrame(emoji_dict, columns=['emoji', 'count'])\n",
        "emoji_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXqqFzEF2pu0",
        "colab_type": "text"
      },
      "source": [
        "### Emoji distribution visualisation on pie chartüòÅüòÅ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7mP0VQAuq_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.express as px\n",
        "fig = px.pie(emoji_df, values='count', names='emoji')\n",
        "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEjIpwTSuovI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = texts_df.Author.unique()\n",
        "for i in range(len(l)):\n",
        "  fa_df = texts_df[texts_df['Author'] == l[i]]\n",
        "  total_emojis_list = list([a for b in fa_df.emoji for a in b])\n",
        "  emoji_dict = dict(Counter(total_emojis_list))\n",
        "  emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "  print('Emoji Distribution for', l[i])\n",
        "  author_emoji_df = pd.DataFrame(emoji_dict, columns=['emoji', 'count'])\n",
        "  fig = px.pie(author_emoji_df, values='count', names='emoji')\n",
        "  fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWtv-fi36bMr",
        "colab_type": "text"
      },
      "source": [
        "More analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe_Z5YK9rsNb",
        "colab_type": "text"
      },
      "source": [
        "Day wise "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMTsC_eZvg1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(i):\n",
        "  l = [ \"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"]\n",
        "  return l[i];\n",
        "day_df=pd.DataFrame(texts_df[\"Text\"])\n",
        "day_df['day_of_date'] = texts_df['Date'].dt.weekday\n",
        "day_df['day_of_date'] = day_df[\"day_of_date\"].apply(f)\n",
        "day_df[\"messagecount\"] = 1\n",
        "day = day_df.groupby(\"day_of_date\").sum()\n",
        "day.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "819m2jtvY2zA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = px.line_polar(day, r='messagecount', theta='day_of_date', line_close=True)\n",
        "fig.update_traces(fill='toself')\n",
        "fig.update_layout(\n",
        "  polar=dict(\n",
        "    radialaxis=dict(\n",
        "      visible=True,\n",
        "    )),\n",
        "  showlegend=False\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHt0guBu8upV",
        "colab_type": "text"
      },
      "source": [
        "### Text with max words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmb8DbXC7Qpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_df.iloc[texts_df['Word_Count'].argmax()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSYaYRnu9tEQ",
        "colab_type": "text"
      },
      "source": [
        "### **Trying Word Cloud**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4YT-IvnBVJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Words = \" \".join(review for review in texts_df.Text)\n",
        "print (\"There are {} words in all the messages.\".format(len(Words)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdDrDmxWOzBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  Endwords = set(STOPWORDS)\n",
        "  Endwords.update([ \"na\", \"ani\",\"ha\",\"la\",\"eh\",\"ne\", \"em\", \"ki\", \"ah\",\"le\",\"ni\",\"lo\",\"Ma\",\"Haa\",\"ni\",\"ra\", \"ga\"])\n",
        "  wordcloud = WordCloud(stopwords=Endwords, background_color=\"white\").generate(Words)\n",
        "  plt.figure( figsize=(10,5))\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}